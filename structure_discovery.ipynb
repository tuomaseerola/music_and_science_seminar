{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGOYgwdkIDdQQ/zMNN0jix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuomaseerola/music_and_science_seminar/blob/master/structure_discovery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structure discovery\n",
        "\n",
        "Examples of structural analysis.\n",
        "\n",
        "_Tuomas Eerola, 18/2/2025_\n"
      ],
      "metadata": {
        "id": "3FE_SHpghGUm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qezibENxf2NT"
      },
      "outputs": [],
      "source": [
        "# pip install librosa\n",
        "# pip install matplotlib\n",
        "from __future__ import print_function\n",
        "import librosa\n",
        "#import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import os\n",
        "import sklearn\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "import IPython.display as ipd\n",
        "import soundfile as sf\n",
        "import io\n",
        "from six.moves.urllib.request import urlopen\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select a piece and downsample for easier processing\n"
      ],
      "metadata": {
        "id": "qgImlIikf5mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/tuomaseerola/music_and_science_seminar/master/Vivaldi.wav\"\n",
        "#url = \"https://raw.githubusercontent.com/tuomaseerola/audio/master/europe_endless_22Khz.wav\"\n",
        "y, sr = sf.read(io.BytesIO(urlopen(url).read()))\n",
        "y = librosa.resample(y, orig_sr=sr, target_sr=22050); sr=22050 # downsampling if the file is long\n",
        "print(sr)\n",
        "plt.figure(figsize=(18, 4))\n",
        "librosa.display.waveshow(y=y,sr=sr)\n",
        "ipd.display(ipd.Audio(data=y, rate=sr))"
      ],
      "metadata": {
        "id": "4j0HJxxaf7pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at the spectrum first"
      ],
      "metadata": {
        "id": "ohS7iSk6f_Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hop_length = 1024\n",
        "D = librosa.amplitude_to_db(np.abs(librosa.stft(y, hop_length=hop_length)),ref=np.max)\n",
        "plt.rcParams['figure.figsize'] = (18,4)\n",
        "librosa.display.specshow(D, y_axis='log', sr=sr, hop_length=hop_length,x_axis='time',cmap='jet')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZVymb1yIgBF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chromagram representation\n",
        "Let's collapse the spectrum into chromagram, which means that the energies across all pitch-classes (C, C#, D,...) are summed. This can be done in many ways, but Constant-Q Transform (CQT) is one of the most common transformations.\n"
      ],
      "metadata": {
        "id": "lBGy2c3ChWxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = librosa.feature.chroma_cqt(y=y, sr=sr, n_chroma=12)\n",
        "plt.figure(figsize=(18, 4))\n",
        "librosa.display.specshow(C, y_axis='chroma',x_axis='time')\n",
        "plt.title('CQT Chromagram')\n",
        "plt.show()\n",
        "ipd.display(ipd.Audio(data=y, rate=sr))"
      ],
      "metadata": {
        "id": "JPFxG0pjGEHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple structure segmentation -- based on pitch-classes\n",
        "Segmenting based on clustering algorithm based on `k` contiguous segments. Let's use pitch-class (chroma) information first and put in an arbitrary number of segment (8?)."
      ],
      "metadata": {
        "id": "sYdT36fLIJCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "bounds = librosa.segment.agglomerative(chroma, 8)\n",
        "bound_times = librosa.frames_to_time(bounds, sr=sr)\n",
        "print(bound_times)"
      ],
      "metadata": {
        "id": "vum8UGulIWsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print the chromagram and the potential boundaries determined by the clustering."
      ],
      "metadata": {
        "id": "ekyGVG3tIc-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.transforms as mpt\n",
        "fig, ax = plt.subplots()\n",
        "trans = mpt.blended_transform_factory(\n",
        "    ax.transData, ax.transAxes)\n",
        "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax)\n",
        "ax.vlines(bound_times, 0, 1, color='lime', linestyle='--',\n",
        "          linewidth=2, alpha=0.9, label='Segment boundaries',\n",
        "          transform=trans)\n",
        "ax.legend()\n",
        "ax.set(title='Chromagram')\n",
        "ipd.display(ipd.Audio(data=y, rate=sr))"
      ],
      "metadata": {
        "id": "PH7OSih9IiK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What about another representations -- MFCCs?\n",
        "And _mel-frequency cepstrum coefficients_ are popular representation of audio signal that incorporates some perceptual processing, namely frequency is represented with mel scale. These are used in many applications, in speech recognition, genre recognition etc."
      ],
      "metadata": {
        "id": "Yuz2w71NJYjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
        "mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
        "\n",
        "bounds = librosa.segment.agglomerative(mfccs, 8)\n",
        "bound_times = librosa.frames_to_time(bounds, sr=sr)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "trans = mpt.blended_transform_factory(ax.transData, ax.transAxes)\n",
        "librosa.display.specshow(mfccs, y_axis='mel', x_axis='time', ax=ax)\n",
        "ax.vlines(bound_times, 0, 1, color='lime', linestyle='--',\n",
        "          linewidth=2, alpha=0.9, label='Segment boundaries',\n",
        "          transform=trans)\n",
        "ax.legend()\n",
        "ax.set(title='MFCCs')\n",
        "ipd.display(ipd.Audio(data=y, rate=sr))"
      ],
      "metadata": {
        "id": "qyMMeF0-JPd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does this correspond to your intuition about the segments?"
      ],
      "metadata": {
        "id": "SGM4YAEYJIAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another representations to calculate the segmenting from? -- Tonnetz\n",
        "Tonnez (\"tone networks\" in German) are a way to represent tonal centroids using 6-dimensions, popularised by neo-Riemannian music theorists."
      ],
      "metadata": {
        "id": "P0aXxsQBKAeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tonnez = librosa.feature.tonnetz(y=y, sr=sr)\n",
        "\n",
        "bounds = librosa.segment.agglomerative(tonnez, 8)\n",
        "bound_times = librosa.frames_to_time(bounds, sr=sr)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "trans = mpt.blended_transform_factory(ax.transData, ax.transAxes)\n",
        "librosa.display.specshow(tonnez, y_axis='tonnetz', x_axis='time', ax=ax,cmap='Accent')\n",
        "ax.vlines(bound_times, 0, 1, color='lime', linestyle='--',\n",
        "          linewidth=3, alpha=0.9, label='Segment boundaries',\n",
        "          transform=trans)\n",
        "ax.set(title='Tonal centroids (Tonnetz)')\n",
        "ipd.display(ipd.Audio(data=y, rate=sr))"
      ],
      "metadata": {
        "id": "mgFyp4P9KTad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Happy with the results?\n",
        "\n",
        "## One more segmentation based on .... rhythm?\n",
        "This time we analyse the rhythm distributions using so-called tempograms."
      ],
      "metadata": {
        "id": "yvjMPO2vKWDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempogram = librosa.feature.tempogram(y=y, sr=sr)\n",
        "\n",
        "bounds = librosa.segment.agglomerative(tempogram, 8)\n",
        "bound_times = librosa.frames_to_time(bounds, sr=sr)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "trans = mpt.blended_transform_factory(ax.transData, ax.transAxes)\n",
        "librosa.display.specshow(tempogram, y_axis='tempo', x_axis='time', ax=ax)\n",
        "ax.vlines(bound_times, 0, 1, color='lime', linestyle='--',\n",
        "          linewidth=3, alpha=0.9, label='Segment boundaries',\n",
        "          transform=trans)\n",
        "ax.set(title='Tempogram')\n",
        "ipd.display(ipd.Audio(data=y, rate=sr))"
      ],
      "metadata": {
        "id": "VcKMLKCPKZlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are more direct techniques such as recurrence matrix and other clever techniques (see [https://librosa.org/doc/latest/segment.html](https://librosa.org/doc/latest/segment.html) for list of techniques and examples."
      ],
      "metadata": {
        "id": "182PEDiXKstO"
      }
    }
  ]
}